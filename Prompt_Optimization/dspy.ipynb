{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dspy\n",
      "  Downloading dspy-0.1.5-py3-none-any.whl.metadata (692 bytes)\n",
      "Collecting dspy-ai==2.4.5 (from dspy)\n",
      "  Downloading dspy_ai-2.4.5-py3-none-any.whl.metadata (36 kB)\n",
      "Requirement already satisfied: backoff~=2.2.1 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dspy-ai==2.4.5->dspy) (2.2.1)\n",
      "Collecting joblib~=1.3.2 (from dspy-ai==2.4.5->dspy)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=0.28.1 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dspy-ai==2.4.5->dspy) (1.35.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dspy-ai==2.4.5->dspy) (2.1.3)\n",
      "Requirement already satisfied: regex in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dspy-ai==2.4.5->dspy) (2024.4.16)\n",
      "Requirement already satisfied: ujson in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dspy-ai==2.4.5->dspy) (5.10.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dspy-ai==2.4.5->dspy) (4.66.4)\n",
      "Collecting datasets<3.0.0,~=2.14.6 (from dspy-ai==2.4.5->dspy)\n",
      "  Downloading datasets-2.14.7-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dspy-ai==2.4.5->dspy) (2.32.3)\n",
      "Collecting optuna (from dspy-ai==2.4.5->dspy)\n",
      "  Downloading optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting pydantic==2.5.0 (from dspy-ai==2.4.5->dspy)\n",
      "  Downloading pydantic-2.5.0-py3-none-any.whl.metadata (174 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic==2.5.0->dspy-ai==2.4.5->dspy) (0.7.0)\n",
      "Collecting pydantic-core==2.14.1 (from pydantic==2.5.0->dspy-ai==2.4.5->dspy)\n",
      "  Downloading pydantic_core-2.14.1-cp311-none-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic==2.5.0->dspy-ai==2.4.5->dspy) (4.8.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy) (16.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy) (0.6)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy)\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: xxhash in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy) (0.70.16)\n",
      "Collecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy)\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy) (0.23.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy) (6.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=0.28.1->dspy-ai==2.4.5->dspy) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=0.28.1->dspy-ai==2.4.5->dspy) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=0.28.1->dspy-ai==2.4.5->dspy) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=0.28.1->dspy-ai==2.4.5->dspy) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->dspy-ai==2.4.5->dspy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->dspy-ai==2.4.5->dspy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->dspy-ai==2.4.5->dspy) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->dspy-ai==2.4.5->dspy) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->dspy-ai==2.4.5->dspy) (0.4.6)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna->dspy-ai==2.4.5->dspy) (1.13.1)\n",
      "Collecting colorlog (from optuna->dspy-ai==2.4.5->dspy)\n",
      "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna->dspy-ai==2.4.5->dspy) (1.4.52)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->dspy-ai==2.4.5->dspy) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->dspy-ai==2.4.5->dspy) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->dspy-ai==2.4.5->dspy) (2023.3)\n",
      "Requirement already satisfied: Mako in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from alembic>=1.5.0->optuna->dspy-ai==2.4.5->dspy) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy) (1.9.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=0.28.1->dspy-ai==2.4.5->dspy) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=0.28.1->dspy-ai==2.4.5->dspy) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy) (3.13.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->dspy-ai==2.4.5->dspy) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna->dspy-ai==2.4.5->dspy) (3.0.1)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets<3.0.0,~=2.14.6->dspy-ai==2.4.5->dspy)\n",
      "  Downloading multiprocess-0.70.15-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\my it store\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna->dspy-ai==2.4.5->dspy) (2.1.3)\n",
      "Downloading dspy-0.1.5-py3-none-any.whl (1.3 kB)\n",
      "Downloading dspy_ai-2.4.5-py3-none-any.whl (197 kB)\n",
      "Downloading pydantic-2.5.0-py3-none-any.whl (407 kB)\n",
      "Downloading pydantic_core-2.14.1-cp311-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   --------------------------------- ------ 1.6/1.9 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 7.0 MB/s eta 0:00:00\n",
      "Downloading datasets-2.14.7-py3-none-any.whl (520 kB)\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
      "Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
      "Downloading multiprocess-0.70.15-py311-none-any.whl (135 kB)\n",
      "Installing collected packages: pydantic-core, joblib, fsspec, dill, colorlog, pydantic, multiprocess, optuna, datasets, dspy-ai, dspy\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.18.4\n",
      "    Uninstalling pydantic_core-2.18.4:\n",
      "      Successfully uninstalled pydantic_core-2.18.4\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.4.0\n",
      "    Uninstalling joblib-1.4.0:\n",
      "      Successfully uninstalled joblib-1.4.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.3.1\n",
      "    Uninstalling fsspec-2024.3.1:\n",
      "      Successfully uninstalled fsspec-2024.3.1\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.8\n",
      "    Uninstalling dill-0.3.8:\n",
      "      Successfully uninstalled dill-0.3.8\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.7.4\n",
      "    Uninstalling pydantic-2.7.4:\n",
      "      Successfully uninstalled pydantic-2.7.4\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.16\n",
      "    Uninstalling multiprocess-0.70.16:\n",
      "      Successfully uninstalled multiprocess-0.70.16\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.20.0\n",
      "    Uninstalling datasets-2.20.0:\n",
      "      Successfully uninstalled datasets-2.20.0\n",
      "Successfully installed colorlog-6.8.2 datasets-2.14.7 dill-0.3.7 dspy-0.1.5 dspy-ai-2.4.5 fsspec-2023.10.0 joblib-1.3.2 multiprocess-0.70.15 optuna-3.6.1 pydantic-2.5.0 pydantic-core-2.14.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-experimental 0.0.62 requires langchain-community<0.3.0,>=0.2.6, but you have langchain-community 0.2.4 which is incompatible.\n",
      "together 1.2.3 requires pydantic<3.0.0,>=2.6.3, but you have pydantic 2.5.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "# Define the task\n",
    "class QA(dspy.Signature):\n",
    "    \"\"\"Answer questions based on the given context.\"\"\"\n",
    "    context = dspy.InputField()\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField()\n",
    "\n",
    "# # Create a basic model\n",
    "# lm = dspy.OpenAILanguageModel(model=\"gpt-3.5-turbo\")\n",
    "lm=dspy.OllamaLocal(model=\"llama3:8b-instruct-q4_K_M\")\n",
    "\n",
    "# lm = dspy.{provider_listed_below}(model=\"your model\", model_request_kwargs=\"...\")\n",
    "# Define the prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'dspy' has no attribute 'Optimize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gold\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m pred\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Create the optimizer\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mdspy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOptimize\u001b[49m(\n\u001b[0;32m     22\u001b[0m     metric\u001b[38;5;241m=\u001b[39mexact_match,\n\u001b[0;32m     23\u001b[0m     module\u001b[38;5;241m=\u001b[39mBasicQA(),\n\u001b[0;32m     24\u001b[0m     trainset\u001b[38;5;241m=\u001b[39mtrain_data,\n\u001b[0;32m     25\u001b[0m     valset\u001b[38;5;241m=\u001b[39mtrain_data,  \u001b[38;5;66;03m# Using the same set for simplicity\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mollama\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     max_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Run the optimization\u001b[39;00m\n\u001b[0;32m     31\u001b[0m optimized_qa \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mrun()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'dspy' has no attribute 'Optimize'"
     ]
    }
   ],
   "source": [
    "class BasicQA(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.qa = QA()\n",
    "\n",
    "    def forward(self, context, question):\n",
    "        return self.qa(context=context, question=question)\n",
    "\n",
    "# Create a dataset for optimization\n",
    "train_data = [\n",
    "    {\"context\": \"The capital of France is Paris.\", \"question\": \"What is the capital of France?\", \"answer\": \"Paris\"},\n",
    "    {\"context\": \"Python is a programming language.\", \"question\": \"What is Python?\", \"answer\": \"A programming language\"},\n",
    "    # Add more examples...\n",
    "]\n",
    "\n",
    "# Define the metric for evaluation\n",
    "def exact_match(gold, pred):\n",
    "    return gold.lower() == pred.lower()\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = dspy.Optimize(\n",
    "    metric=exact_match,\n",
    "    module=BasicQA(),\n",
    "    trainset=train_data,\n",
    "    valset=train_data,  # Using the same set for simplicity\n",
    "    optimizer=\"ollama\",\n",
    "    max_rounds=5\n",
    ")\n",
    "\n",
    "# Run the optimization\n",
    "optimized_qa = optimizer.run()\n",
    "\n",
    "# Test the optimized model\n",
    "context = \"The Eiffel Tower is located in Paris, France.\"\n",
    "question = \"Where is the Eiffel Tower located?\"\n",
    "\n",
    "result = optimized_qa(context=context, question=question)\n",
    "print(f\"Optimized model answer: {result.answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement llama_cpp (from versions: none)\n",
      "ERROR: No matching distribution found for llama_cpp\n"
     ]
    }
   ],
   "source": [
    "!pip install llama_cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'dspy' has no attribute 'LM'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdspy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mollama\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mOllamaModel\u001b[39;00m(\u001b[43mdspy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLM\u001b[49m):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama2\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m=\u001b[39m model_name\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'dspy' has no attribute 'LM'"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import ollama\n",
    "\n",
    "class OllamaModel(dspy.LM):\n",
    "    def __init__(self, model_name=\"llama2\"):\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def basic_request(self, prompt, **kwargs):\n",
    "        response = ollama.generate(model=self.model_name, prompt=prompt)\n",
    "        return response['response']\n",
    "\n",
    "    def __call__(self, prompt, **kwargs):\n",
    "        response = self.basic_request(prompt, **kwargs)\n",
    "        return dspy.Completion(text=response, logprob=0)  # Ollama doesn't provide logprobs, so we use 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Ollama to run the LLaMA model\n",
    "lm = OllamaModel(model_name=\"llama3:8b-instruct-q4_K_M\")  # or whatever LLaMA model you have in Ollama\n",
    "\n",
    "# Define the task (same as before)\n",
    "class QA(dspy.Signature):\n",
    "    \"\"\"Answer questions based on the given context.\"\"\"\n",
    "    context = dspy.InputField()\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField()\n",
    "\n",
    "# Define the prompt (same as before)\n",
    "class BasicQA(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.qa = QA()\n",
    "\n",
    "    def forward(self, context, question):\n",
    "        return self.qa(context=context, question=question)\n",
    "\n",
    "# Create a dataset for optimization (same as before)\n",
    "train_data = [\n",
    "    {\"context\": \"The capital of France is Paris.\", \"question\": \"What is the capital of France?\", \"answer\": \"Paris\"},\n",
    "    {\"context\": \"Python is a programming language.\", \"question\": \"What is Python?\", \"answer\": \"A programming language\"},\n",
    "    # Add more examples...\n",
    "]\n",
    "\n",
    "# Define the metric for evaluation (same as before)\n",
    "def exact_match(gold, pred):\n",
    "    return gold.lower() == pred.lower()\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = dspy.Optimize(\n",
    "    metric=exact_match,\n",
    "    module=BasicQA(),\n",
    "    trainset=train_data,\n",
    "    valset=train_data,  # Using the same set for simplicity\n",
    "    optimizer=\"rm\",  # Use a different optimizer as \"openai\" might not work with local models\n",
    "    max_rounds=5\n",
    ")\n",
    "\n",
    "# Run the optimization\n",
    "optimized_qa = optimizer.run()\n",
    "\n",
    "# Test the optimized model\n",
    "context = \"The Eiffel Tower is located in Paris, France.\"\n",
    "question = \"Where is the Eiffel Tower located?\"\n",
    "\n",
    "result = optimized_qa(context=context, question=question)\n",
    "print(f\"Optimized model answer: {result.answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Module.__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     summary \u001b[38;5;241m=\u001b[39m dspy\u001b[38;5;241m.\u001b[39mOutputField()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Create a basic module\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m summarizer \u001b[38;5;241m=\u001b[39m \u001b[43mdspy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSummarize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Example text to summarize\u001b[39;00m\n\u001b[0;32m     16\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDSPy is a framework for solving AI tasks using language models and retrieval models. It allows developers to write task-specific programs and optimize them automatically.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: Module.__init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "# Define a simple language model\n",
    "lm = dspy.OpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Define a signature for our task\n",
    "class Summarize(dspy.Signature):\n",
    "    \"\"\"Summarize the given text.\"\"\"\n",
    "    text = dspy.InputField()\n",
    "    summary = dspy.OutputField()\n",
    "\n",
    "# Create a basic module\n",
    "summarizer = dspy.Module(Summarize)\n",
    "\n",
    "# Example text to summarize\n",
    "text = \"DSPy is a framework for solving AI tasks using language models and retrieval models. It allows developers to write task-specific programs and optimize them automatically.\"\n",
    "\n",
    "# Optimize the module\n",
    "optimized_summarizer = dspy.ChainOfThought(summarizer)\n",
    "\n",
    "# Use the optimized module\n",
    "result = optimized_summarizer(text=text)\n",
    "print(result.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MY IT STORE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f299111a2bd41e19f9d1e870651d6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MY IT STORE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\MY IT STORE\\.cache\\huggingface\\hub\\models--t5-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6147b1356644b4a863c18d365ecd59d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f045687e486495e891219b47068489a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3712c3aea83e4b47bc0feb9747d29377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5d628f96694312b42d13d862f22839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'dspy' has no attribute 'Optimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m qa_module \u001b[38;5;241m=\u001b[39m dspy\u001b[38;5;241m.\u001b[39mPredict(QuestionAnswer, model\u001b[38;5;241m=\u001b[39mmodel, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Define an optimizer for the module to refine the prompt and model weights\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mdspy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOptimizer\u001b[49m(qa_module)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Sample input\u001b[39;00m\n\u001b[0;32m     21\u001b[0m input_data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the capital of France?\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'dspy' has no attribute 'Optimizer'"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Load a local model (for example, T5-base)\n",
    "model_name = \"t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Define a signature for a simple Q&A task\n",
    "class QuestionAnswer(dspy.Signature):\n",
    "    question = dspy.InputField(desc=\"The question to be answered\")\n",
    "    answer = dspy.OutputField(desc=\"The model's answer\")\n",
    "\n",
    "# Create a DSPy module using the signature\n",
    "qa_module = dspy.Predict(QuestionAnswer, model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Define an optimizer for the module to refine the prompt and model weights\n",
    "optimizer = dspy.Optimizer(qa_module)\n",
    "\n",
    "# Sample input\n",
    "input_data = {\"question\": \"What is the capital of France?\"}\n",
    "\n",
    "# Run optimization process\n",
    "optimized_output = optimizer.optimize(input_data)\n",
    "\n",
    "# Print the optimized answer\n",
    "print(\"Optimized Answer:\", optimized_output.answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "turbo=dspy.OllamaLocal(model=\"llama3.1:8b-instruct-q4_K_M\")\n",
    "dspy.settings.configure(lm=turbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import dspy\n",
    "from dspy.datasets import HotPotQA\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "from dspy.evaluate.evaluate import Evaluate\n",
    "from dsp.utils import deduplicate\n",
    "from rich import print\n",
    "\n",
    "# turbo = dspy.OpenAI(model='gpt-3.5-turbo')\n",
    "\n",
    "turbo=dspy.OllamaLocal(model=\"llama3.1:8b-instruct-q4_K_M\",timeout_s=1000)\n",
    "colbertv2_wiki17_abstracts = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25abcbd5da64c34ab9db92523596044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ee7c8e5bde4b2fb7bc921d31db96eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/566M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b44c1f2fb634f2eace0ecfb8c60f13e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/47.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704756043ccf4edc82d608725063df60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/46.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d0b58af4404d71bb220afe5e2919f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/90447 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79be63e2c1a442579bfe4beb4b8d1ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/7405 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34672e6fc1cc4bfd910e2909a098778e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7405 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MY IT STORE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "dspy.settings.configure(lm=turbo, rm=colbertv2_wiki17_abstracts)\n",
    "dataset = HotPotQA(train_seed=1, train_size=20, eval_seed=2023, dev_size=50, test_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m20\u001b[0m \u001b[1;36m50\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: At My Window was released by which American singer-songwriter?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: At My Window was released by which American singer-songwriter?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Answer: John Townes Van Zandt\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Answer: John Townes Van Zandt\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Answer: English\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Answer: English\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Relevant Wikipedia Titles: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'Robert Irvine'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'Restaurant: Impossible'</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Relevant Wikipedia Titles: \u001b[1m{\u001b[0m\u001b[32m'Robert Irvine'\u001b[0m, \u001b[32m'Restaurant: Impossible'\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">For this dataset, training examples have input keys <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'question'</span><span style=\"font-weight: bold\">]</span> and label keys <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "For this dataset, training examples have input keys \u001b[1m[\u001b[0m\u001b[32m'question'\u001b[0m\u001b[1m]\u001b[0m and label keys \u001b[1m[\u001b[0m\u001b[32m'answer'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">For this dataset, dev examples have input keys <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'question'</span><span style=\"font-weight: bold\">]</span> and label keys <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'gold_titles'</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "For this dataset, dev examples have input keys \u001b[1m[\u001b[0m\u001b[32m'question'\u001b[0m\u001b[1m]\u001b[0m and label keys \u001b[1m[\u001b[0m\u001b[32m'answer'\u001b[0m, \u001b[32m'gold_titles'\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainset = [x.with_inputs('question') for x in dataset.train]\n",
    "devset = [x.with_inputs('question') for x in dataset.dev]\n",
    "\n",
    "print(len(trainset), len(devset))\n",
    "\n",
    "train_example = trainset[0]\n",
    "print(f\"Question: {train_example.question}\")\n",
    "print(f\"Answer: {train_example.answer}\")\n",
    "\n",
    "dev_example = devset[18]\n",
    "print(f\"Question: {dev_example.question}\")\n",
    "print(f\"Answer: {dev_example.answer}\")\n",
    "print(f\"Relevant Wikipedia Titles: {dev_example.gold_titles}\")\n",
    "\n",
    "print(f\"For this dataset, training examples have input keys {train_example.inputs().keys()} and label keys {train_example.labels().keys()}\")\n",
    "print(f\"For this dataset, dev examples have input keys {dev_example.inputs().keys()} and label keys {dev_example.labels().keys()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predicted Answer: Robert Irvine\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Predicted Answer: Robert Irvine\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\n",
      "Answer:\u001b[32m Robert Irvine\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Thought: \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Thought: \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Predicted Answer: Question: What is the nationality of the chef and restaurateur featured in Restaurant: \n",
       "Impossible?\n",
       "Reasoning: Let's think step by step in order to determine his nationality. We know he has a British accent and \n",
       "background, so<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "Answer: British.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Predicted Answer: Question: What is the nationality of the chef and restaurateur featured in Restaurant: \n",
       "Impossible?\n",
       "Reasoning: Let's think step by step in order to determine his nationality. We know he has a British accent and \n",
       "background, so\u001b[33m...\u001b[0m\n",
       "Answer: British.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Top <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> passages for question: What is the nationality of the chef and restaurateur featured in Restaurant: \n",
       "Impossible? \n",
       " ------------------------------ \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Top \u001b[1;36m3\u001b[0m passages for question: What is the nationality of the chef and restaurateur featured in Restaurant: \n",
       "Impossible? \n",
       " ------------------------------ \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span> Restaurant: Impossible | Restaurant: Impossible is an American reality television series, featuring chef and \n",
       "restaurateur Robert Irvine, that aired on Food Network from <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2011</span> to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2016</span>. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m Restaurant: Impossible | Restaurant: Impossible is an American reality television series, featuring chef and \n",
       "restaurateur Robert Irvine, that aired on Food Network from \u001b[1;36m2011\u001b[0m to \u001b[1;36m2016\u001b[0m. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span> Jean Joho | Jean Joho is a French-American chef and restaurateur. He is chef/proprietor of Everest in Chicago \n",
       "<span style=\"font-weight: bold\">(</span>founded in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1986</span><span style=\"font-weight: bold\">)</span>, Paris Club Bistro &amp; Bar and Studio Paris in Chicago, The Eiffel Tower Restaurant in Las Vegas, \n",
       "and Brasserie JO in Boston. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m Jean Joho | Jean Joho is a French-American chef and restaurateur. He is chef/proprietor of Everest in Chicago \n",
       "\u001b[1m(\u001b[0mfounded in \u001b[1;36m1986\u001b[0m\u001b[1m)\u001b[0m, Paris Club Bistro & Bar and Studio Paris in Chicago, The Eiffel Tower Restaurant in Las Vegas, \n",
       "and Brasserie JO in Boston. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">]</span> List of Restaurant: Impossible episodes | This is the list of the episodes for the American cooking and reality \n",
       "television series <span style=\"color: #008000; text-decoration-color: #008000\">\"Restaurant Impossible\"</span>, produced by Food Network. The premise of the series is that within two \n",
       "days and on a budget of $<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">000</span>, celebrity chef Robert Irvine renovates a failing American restaurant with the goal\n",
       "of helping to restore it to profitability and prominence. Irvine is assisted by a designer <span style=\"font-weight: bold\">(</span>usually Taniya Nayak, \n",
       "Cheryl Torrenueva, or Lynn Keagan, but sometimes Vanessa De Leon, Krista Watterworth, Yvette Irene, or Nicole \n",
       "Faccuito<span style=\"font-weight: bold\">)</span>, along with general contractor Tom Bury, who sometimes does double duty as both general contractor and \n",
       "designer. After assessing the problems with the restaurant, Robert Irvine typically creates a plan for the new \n",
       "decor, oversees the cleaning of the restaurant, reduces the size of the menu and improves the food, develops a \n",
       "promotional activity, educates the restaurant's owners, or trains the staff, as needed by each restaurant. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m3\u001b[0m\u001b[1m]\u001b[0m List of Restaurant: Impossible episodes | This is the list of the episodes for the American cooking and reality \n",
       "television series \u001b[32m\"Restaurant Impossible\"\u001b[0m, produced by Food Network. The premise of the series is that within two \n",
       "days and on a budget of $\u001b[1;36m10\u001b[0m,\u001b[1;36m000\u001b[0m, celebrity chef Robert Irvine renovates a failing American restaurant with the goal\n",
       "of helping to restore it to profitability and prominence. Irvine is assisted by a designer \u001b[1m(\u001b[0musually Taniya Nayak, \n",
       "Cheryl Torrenueva, or Lynn Keagan, but sometimes Vanessa De Leon, Krista Watterworth, Yvette Irene, or Nicole \n",
       "Faccuito\u001b[1m)\u001b[0m, along with general contractor Tom Bury, who sometimes does double duty as both general contractor and \n",
       "designer. After assessing the problems with the restaurant, Robert Irvine typically creates a plan for the new \n",
       "decor, oversees the cleaning of the restaurant, reduces the size of the menu and improves the food, develops a \n",
       "promotional activity, educates the restaurant's owners, or trains the staff, as needed by each restaurant. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">History of the FIFA World Cup | The FIFA World Cup was first held in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1930</span>, when FIFA president Jules Rimet decided \n",
       "to stage an international football tournament. The inaugural edition, held in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1930</span>, was contested as a final \n",
       "tournament of only thirteen teams invited by the organization. Since then, the World Cup has experienced successive\n",
       "expansions and format remodeling to its current <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>-team final tournament preceded by a two-year qualifying process,\n",
       "involving over <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">200</span> teams from around the world.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "History of the FIFA World Cup | The FIFA World Cup was first held in \u001b[1;36m1930\u001b[0m, when FIFA president Jules Rimet decided \n",
       "to stage an international football tournament. The inaugural edition, held in \u001b[1;36m1930\u001b[0m, was contested as a final \n",
       "tournament of only thirteen teams invited by the organization. Since then, the World Cup has experienced successive\n",
       "expansions and format remodeling to its current \u001b[1;36m32\u001b[0m-team final tournament preceded by a two-year qualifying process,\n",
       "involving over \u001b[1;36m200\u001b[0m teams from around the world.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class BasicQA(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
    "\n",
    "generate_answer = dspy.Predict(BasicQA)\n",
    "pred = generate_answer(question=dev_example.question)\n",
    "print(f\"Question: {dev_example.question}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")\n",
    "\n",
    "turbo.inspect_history(n=1)\n",
    "\n",
    "generate_answer_with_chain_of_thought = dspy.ChainOfThought(BasicQA)\n",
    "pred = generate_answer_with_chain_of_thought(question=dev_example.question)\n",
    "print(f\"Question: {dev_example.question}\")\n",
    "print(f\"Thought: {pred.rationale.split('.', 1)[1].strip()}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")\n",
    "\n",
    "retrieve = dspy.Retrieve(k=3)\n",
    "topK_passages = retrieve(dev_example.question).passages\n",
    "\n",
    "print(f\"Top {retrieve.k} passages for question: {dev_example.question} \\n\", '-' * 30, '\\n')\n",
    "\n",
    "for idx, passage in enumerate(topK_passages):\n",
    "    print(f'{idx+1}]', passage, '\\n')\n",
    "\n",
    "print(retrieve(\"When was the first FIFA World Cup held?\").passages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to run or to evaluate example Example({'question': 'At My Window was released by which American singer-songwriter?', 'answer': 'John Townes Van Zandt'}) (input_keys={'question'}) with <function validate_context_and_answer at 0x000001EA8499D620> due to HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=120).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to run or to evaluate example Example({'question': 'which  American actor was Candace Kita  guest starred with ', 'answer': 'Bill Murray'}) (input_keys={'question'}) with <function validate_context_and_answer at 0x000001EA8499D620> due to HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=120).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [05:23<50:31, 168.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to run or to evaluate example Example({'question': 'Which of these publications was most recently published, Who Put the Bomp or Self?', 'answer': 'Self'}) (input_keys={'question'}) with <function validate_context_and_answer at 0x000001EA8499D620> due to HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=120).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to run or to evaluate example Example({'question': 'The Victorians - Their Story In Pictures is a documentary series written by an author born in what year?', 'answer': '1950'}) (input_keys={'question'}) with <function validate_context_and_answer at 0x000001EA8499D620> due to HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=120).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
    "\n",
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)\n",
    "\n",
    "def validate_context_and_answer(example, pred, trace=None):\n",
    "    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n",
    "    answer_PM = dspy.evaluate.answer_passage_match(example, pred)\n",
    "    return answer_EM and answer_PM\n",
    "\n",
    "teleprompter = BootstrapFewShot(metric=validate_context_and_answer)\n",
    "compiled_rag = teleprompter.compile(RAG(), trainset=trainset)\n",
    "\n",
    "my_question = \"What castle did David Gregory inherit?\"\n",
    "pred = compiled_rag(my_question)\n",
    "\n",
    "print(f\"Question: {my_question}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")\n",
    "print(f\"Retrieved Contexts (truncated): {[c[:200] + '...' for c in pred.context]}\")\n",
    "\n",
    "turbo.inspect_history(n=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, parameter in compiled_rag.named_predictors():\n",
    "    print(name)\n",
    "    print(parameter.demos[0])\n",
    "    print()\n",
    "\n",
    "# Evaluating the Answers\n",
    "evaluate_on_hotpotqa = Evaluate(devset=devset, num_threads=1, display_progress=True, display_table=5)\n",
    "metric = dspy.evaluate.answer_exact_match\n",
    "evaluate_on_hotpotqa(compiled_rag, metric=metric)\n",
    "\n",
    "def gold_passages_retrieved(example, pred, trace=None):\n",
    "    gold_titles = set(map(dspy.evaluate.normalize_text, example['gold_titles']))\n",
    "    found_titles = set(map(dspy.evaluate.normalize_text, [c.split(' | ')[0] for c in pred.context]))\n",
    "    return gold_titles.issubset(found_titles)\n",
    "\n",
    "compiled_rag_retrieval_score = evaluate_on_hotpotqa(compiled_rag, metric=gold_passages_retrieved)\n",
    "\n",
    "class GenerateSearchQuery(dspy.Signature):\n",
    "    \"\"\"Write a simple search query that will help answer a complex question.\"\"\"\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    query = dspy.OutputField()\n",
    "\n",
    "class SimplifiedBaleen(dspy.Module):\n",
    "    def __init__(self, passages_per_hop=3, max_hops=2):\n",
    "        super().__init__()\n",
    "        self.generate_query = [dspy.ChainOfThought(GenerateSearchQuery) for _ in range(max_hops)]\n",
    "        self.retrieve = dspy.Retrieve(k=passages_per_hop)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "        self.max_hops = max_hops\n",
    "    \n",
    "    def forward(self, question):\n",
    "        context = []\n",
    "        for hop in range(self.max_hops):\n",
    "            query = self.generate_query[hop](context=context, question=question).query\n",
    "            passages = self.retrieve(query).passages\n",
    "            context = deduplicate(context + passages)\n",
    "        pred = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=pred.answer)\n",
    "\n",
    "uncompiled_baleen = SimplifiedBaleen()  # uncompiled (i.e., zero-shot) program\n",
    "pred = uncompiled_baleen(my_question)\n",
    "print(f\"Question: {my_question}\")\n",
    "print(f\"Predicted Answer: {pred.answer}\")\n",
    "print(f\"Retrieved Contexts (truncated): {[c[:200] + '...' for c in pred.context]}\")\n",
    "\n",
    "turbo.inspect_history(n=3)\n",
    "\n",
    "def validate_context_and_answer_and_hops(example, pred, trace=None):\n",
    "    if not dspy.evaluate.answer_exact_match(example, pred): return False\n",
    "    if not dspy.evaluate.answer_passage_match(example, pred): return False\n",
    "    hops = [example.question] + [outputs.query for *_, outputs in trace if 'query' in outputs]\n",
    "    if max([len(h) for h in hops]) > 100: return False\n",
    "    if any(dspy.evaluate.answer_exact_match_str(hops[idx], hops[:idx], frac=0.8) for idx in range(2, len(hops))): return False\n",
    "    return True\n",
    "\n",
    "teleprompter = BootstrapFewShot(metric=validate_context_and_answer_and_hops)\n",
    "compiled_baleen = teleprompter.compile(SimplifiedBaleen(), teacher=SimplifiedBaleen(passages_per_hop=2), trainset=trainset)\n",
    "uncompiled_baleen_retrieval_score = evaluate_on_hotpotqa(uncompiled_baleen, metric=gold_passages_retrieved)\n",
    "compiled_baleen_retrieval_score = evaluate_on_hotpotqa(compiled_baleen, metric=gold_passages_retrieved)\n",
    "\n",
    "print(f\"## Retrieval Score for RAG: {compiled_rag_retrieval_score}\")\n",
    "print(f\"## Retrieval Score for uncompiled Baleen: {uncompiled_baleen_retrieval_score}\")\n",
    "print(f\"## Retrieval Score for compiled Baleen: {compiled_baleen_retrieval_score}\")\n",
    "\n",
    "compiled_baleen(\"How many storeys are in the castle that David Gregory inherited?\")\n",
    "turbo.inspect_history(n=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
