{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMuzDnAESnqIHX68ArQHRwL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Sliding window chunking"],"metadata":{"id":"0YNx51IzJl0Z"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TAC3T_b3JelT","executionInfo":{"status":"ok","timestamp":1719902035318,"user_tz":-300,"elapsed":6,"user":{"displayName":"Chaudhry Waleed","userId":"08740004565793722365"}},"outputId":"5a2b98e0-8231-4033-f19b-4deb11680d86"},"outputs":[{"output_type":"stream","name":"stdout","text":["['This is an', 'is an exam', ' example t', 'ple text f', 'ext for sl', 'or sliding', 'iding wind', ' window ch', 'ow chunkin']\n"]}],"source":["def sliding_window_chunk(text, window_size, step_size):\n","    chunks = []\n","    for i in range(0, len(text) - window_size + 1, step_size):\n","        chunks.append(text[i:i + window_size])\n","    return chunks\n","\n","text = \"This is an example text for sliding window chunking.\"\n","chunks = sliding_window_chunk(text, 10, 5)\n","print(chunks)\n"]},{"cell_type":"markdown","source":["# Semantic chunking (sentence wise)"],"metadata":{"id":"blUjM_a4JyNk"}},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import sent_tokenize\n","\n","def semantic_chunk(text):\n","    return sent_tokenize(text)\n","\n","text = \"This is an example text. It demonstrates semantic chunking. Each sentence is a chunk.\"\n","chunks = semantic_chunk(text)\n","print(chunks)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JwnehIteJxp4","executionInfo":{"status":"ok","timestamp":1719902112085,"user_tz":-300,"elapsed":3395,"user":{"displayName":"Chaudhry Waleed","userId":"08740004565793722365"}},"outputId":"1c91bc43-bea0-4188-fbcd-543d03d02840"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["['This is an example text.', 'It demonstrates semantic chunking.', 'Each sentence is a chunk.']\n"]}]},{"cell_type":"markdown","source":["# Fixed Size Chunking"],"metadata":{"id":"uqyRs1aCKGz_"}},{"cell_type":"code","source":["def fixed_length_chunk(text, chunk_size):\n","    return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n","\n","text = \"This is an example text for fixed-length chunking.\"\n","chunks = fixed_length_chunk(text, 10)\n","print(chunks)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RzBmgQxYKGdl","executionInfo":{"status":"ok","timestamp":1719902194766,"user_tz":-300,"elapsed":426,"user":{"displayName":"Chaudhry Waleed","userId":"08740004565793722365"}},"outputId":"f7ae7c09-f598-460b-dd41-d265837ab745"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["['This is an', ' example t', 'ext for fi', 'xed-length', ' chunking.']\n"]}]},{"cell_type":"markdown","source":["# Topic Based Chunking"],"metadata":{"id":"8PkQd9UNKPLL"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.decomposition import LatentDirichletAllocation\n","\n","def topic_based_chunk(text, num_topics):\n","    vectorizer = CountVectorizer(stop_words='english')\n","    X = vectorizer.fit_transform([text])\n","    lda = LatentDirichletAllocation(n_components=num_topics, random_state=0)\n","    lda.fit(X)\n","    topics = lda.transform(X)\n","    return topics\n","\n","text = \"This is an example text for topic-based chunking. It demonstrates how text can be divided based on topics.\"\n","chunks = topic_based_chunk(text, 2)\n","print(chunks)\n"],"metadata":{"id":"OVNIy0mgKPZP","executionInfo":{"status":"ok","timestamp":1719902220705,"user_tz":-300,"elapsed":387,"user":{"displayName":"Chaudhry Waleed","userId":"08740004565793722365"}},"outputId":"e906e49a-4e55-4d80-fee4-efbda4c60320","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.94643071 0.05356929]]\n"]}]}]}